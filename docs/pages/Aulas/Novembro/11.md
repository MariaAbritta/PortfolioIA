# üìö Aula - Parte 2: Estrutura dos agentes

## üîë **Conceitos-Chave**

- **[Conceito 1]**: [Defini√ß√£o ou explica√ß√£o]
- **[Conceito 2]**: [Defini√ß√£o ou explica√ß√£o]

---

## ‚úçÔ∏è **Anota√ß√£o da Aula**

### Arquitetura do Agente

Na √°rea de Intelig√™ncia Artificial, o conceito de **arquitetura do agente** refere-se √† base f√≠sica ou computacional que permite que um agente funcione. Esse agente pode ser entendido como qualquer sistema que perceba o ambiente ao seu redor por meio de sensores e que atue sobre esse ambiente utilizando atuadores, com o objetivo de atingir suas metas.

#### Componentes do Agente

1. **Programa do agente**:
   - √â o software ou algoritmo que define como o agente processa as informa√ß√µes recebidas pelos sensores e determina as a√ß√µes que devem ser executadas pelos atuadores. 
   - O programa √© respons√°vel por implementar a l√≥gica ou a fun√ß√£o do agente, que pode variar de simples respostas a est√≠mulos at√© decis√µes complexas baseadas em aprendizado.

2. **Arquitetura do agente**:
   - Refere-se ao hardware ou ao dispositivo computacional no qual o programa do agente est√° implementado. 
   - Inclui os **sensores**, que captam informa√ß√µes do ambiente, e os **atuadores**, que interagem fisicamente com o ambiente.

#### Rela√ß√£o entre Programa e Arquitetura

A rela√ß√£o entre o programa e a arquitetura √© sintetizada na equa√ß√£o:  
**AGENTE = PROGRAMA + ARQUITETURA**

Ou seja, um agente precisa tanto da capacidade computacional (hardware) quanto de uma l√≥gica ou algoritmo (software) para operar efetivamente.

### Programa Agente

Um **Programa Agente** define como um agente se comporta ao tomar decis√µes com base nas percep√ß√µes obtidas de seu ambiente. Esse programa implementa a fun√ß√£o do agente, determinando quais a√ß√µes ele deve realizar para alcan√ßar seus objetivos.

#### Problema com Abordagem Orientada por Tabela

Uma abordagem ing√™nua seria construir um agente baseado em uma **tabela de consulta** (**lookup table**), onde cada entrada da tabela corresponde a uma combina√ß√£o de percep√ß√µes e a√ß√µes associadas.

#### Problemas dessa abordagem:
1. **Explos√£o combinat√≥ria**:
   - O n√∫mero de entradas cresce exponencialmente com o n√∫mero de estados poss√≠veis. Exemplo: Uma lookup table para o jogo de xadrez exigiria mais entradas do que √°tomos no universo.
2. **Inefici√™ncia**:
   - O armazenamento e a consulta das entradas seriam invi√°veis.
3. **Falta de generaliza√ß√£o**:
   - Situa√ß√µes in√©ditas n√£o podem ser tratadas.

#### Solu√ß√£o: Estrat√©gias para Programas Menores

1. **Algoritmos eficientes**:
   - Substituem tabelas por f√≥rmulas ou m√©todos r√°pidos, como o **M√©todo de Newton** para c√°lculo de raiz quadrada.

2. **Modelos baseados em regras**:
   - Conjuntos de regras descrevem como agir em diferentes situa√ß√µes, economizando espa√ßo.

3. **Aprendizado de m√°quina**:
   - T√©cnicas como redes neurais ou aprendizado por refor√ßo permitem criar agentes que aprendem a agir com efici√™ncia.

4. **Estruturas de dados otimizadas**:
   - Estruturas como √°rvores de decis√£o ou grafos s√£o mais compactas e r√°pidas.

Essas estrat√©gias tornam os programas agentes mais eficientes, escal√°veis e adapt√°veis.

### Programa Agente - Princ√≠pios

Os programas agentes podem ser classificados com base nos princ√≠pios utilizados para tomar decis√µes e agir no ambiente. Os principais tipos s√£o:

#### 1. Agentes de Reflexo Simples (Simple Reflex Agents)
- **Princ√≠pio**: Reagem diretamente √†s percep√ß√µes do ambiente com base em regras predefinidas ("se-ent√£o").  
- **Caracter√≠sticas**:
  - N√£o possuem mem√≥ria.
  - N√£o consideram o hist√≥rico das percep√ß√µes.
  - √öteis em ambientes simples e completamente observ√°veis.  
- **Exemplo**: Um termostato que liga o ar-condicionado quando a temperatura ultrapassa um valor predefinido.

#### 2. Agentes de Reflexo Baseado em Modelo (Model-based Reflex Agents)
- **Princ√≠pio**: Reagem com base em percep√ß√µes atuais e informa√ß√µes armazenadas sobre o estado do ambiente.  
- **Caracter√≠sticas**:
  - Possuem um **modelo do mundo**, que permite inferir o estado do ambiente.
  - Consideram as mudan√ßas no ambiente para decidir suas a√ß√µes.  
- **Exemplo**: Um rob√¥ que desvia de obst√°culos ao navegar em um ambiente parcialmente conhecido.

#### 3. Agentes Baseados em Objetivos (Goal-based Agents)
- **Princ√≠pio**: Tomam decis√µes considerando as metas que desejam alcan√ßar.  
- **Caracter√≠sticas**:
  - Precisam de uma defini√ß√£o clara dos objetivos.
  - Podem planejar a√ß√µes considerando o impacto no alcance das metas.  
- **Exemplo**: Um agente GPS que calcula a rota mais curta para chegar ao destino.

#### 4. Agentes Utilit√°rios (Utility-based Agents)
- **Princ√≠pio**: Avaliam m√∫ltiplas op√ß√µes e escolhem a a√ß√£o que maximiza sua utilidade (satisfa√ß√£o ou benef√≠cio).  
- **Caracter√≠sticas**:
  - Utilizam uma **fun√ß√£o utilidade** para medir o qu√£o "bom" √© um estado ou uma a√ß√£o.
  - S√£o capazes de lidar com situa√ß√µes onde h√° m√∫ltiplos objetivos ou incerteza.  
- **Exemplo**: Um carro aut√¥nomo que escolhe a rota mais r√°pida considerando o tr√¢nsito e o consumo de combust√≠vel.

### Agente de Reflexo Simples

Um **Agente de Reflexo Simples** toma decis√µes com base apenas na **percep√ß√£o atual** do ambiente, sem considerar o hist√≥rico de percep√ß√µes ou estados anteriores. Ele segue regras simples do tipo **"if this then do that"**.

#### Caracter√≠sticas principais:
1. **Baseado apenas na percep√ß√£o atual**:
   - N√£o mant√©m mem√≥ria ou hist√≥rico sobre o que aconteceu no passado.
2. **Regra de a√ß√£o (if-then)**:
   - Seu comportamento √© guiado por um conjunto fixo de regras de decis√£o.
3. **Decis√µes limitadas**:
   - S√≥ funciona em ambientes onde as percep√ß√µes atuais fornecem informa√ß√µes suficientes para tomar decis√µes corretas.
4. **Ambiente totalmente observ√°vel**:
   - Requer um ambiente onde o agente possa acessar todas as informa√ß√µes relevantes a partir de suas percep√ß√µes.

#### Limita√ß√µes
- N√£o funciona bem em ambientes parcialmente observ√°veis ou complexos, onde as a√ß√µes dependem de informa√ß√µes passadas ou previs√µes futuras.

#### Exemplo: Aspirador de P√≥ Autom√°tico com Randomiza√ß√£o

Imagine um aspirador de p√≥ autom√°tico que se movimenta em um ambiente completamente observ√°vel (como uma sala sem m√≥veis). Ele segue regras simples como:

1. **Regra de movimento**:
   - "Se a posi√ß√£o atual estiver limpa, mova-se para uma posi√ß√£o aleat√≥ria."
   - "Se a posi√ß√£o atual estiver suja, limpe-a."

2. **Randomiza√ß√£o**:
   - Ap√≥s concluir uma a√ß√£o, o aspirador escolhe aleatoriamente uma dire√ß√£o para se movimentar (exemplo: para frente, para tr√°s, ou para os lados).

Embora funcional em ambientes simples, este agente pode ser ineficiente, pois n√£o considera trajet√≥rias planejadas ou estados visitados anteriormente.

### Agente de Reflexo Baseado em Modelo

O **Agente de Reflexo Baseado em Modelo** √© capaz de lidar com **ambientes parcialmente observ√°veis** utilizando um **estado interno** para armazenar informa√ß√µes sobre o ambiente que n√£o podem ser diretamente percebidas no momento.

#### Caracter√≠sticas principais:
1. **Ambiente parcialmente observ√°vel**:
   - Lida com situa√ß√µes em que as percep√ß√µes atuais n√£o fornecem todas as informa√ß√µes necess√°rias sobre o ambiente.
2. **Estado interno**:
   - Um componente interno armazena informa√ß√µes relevantes sobre o ambiente, baseando-se no hist√≥rico de percep√ß√µes e a√ß√µes anteriores.
3. **Modelo transit√≥rio**:
   - O agente utiliza um modelo que descreve como suas a√ß√µes afetam o ambiente, ajudando a prever mudan√ßas futuras.
4. **Modelo sensorial**:
   - Define as capacidades e limita√ß√µes dos sensores, auxiliando na interpreta√ß√£o das percep√ß√µes.

#### Funcionamento

1. **Atualiza√ß√£o do estado interno**:
   - Baseia-se nas percep√ß√µes atuais e no estado interno anterior.
2. **Tomada de decis√£o**:
   - A partir do estado interno atualizado, o agente utiliza regras ou algoritmos para determinar a pr√≥xima a√ß√£o.

#### Exemplo: Rob√¥ que Desvia de Obst√°culos

Imagine um rob√¥ que navega em um ambiente parcialmente observ√°vel, como um armaz√©m com caixas e paredes. Ele segue estas etapas:

1. **Percep√ß√£o**:
   - Detecta obst√°culos √† frente usando sensores limitados (como ultrassom ou infravermelho).

2. **Estado interno**:
   - Mant√©m um mapa interno do ambiente, baseado em informa√ß√µes coletadas anteriormente.

3. **Modelo transit√≥rio**:
   - Usa o hist√≥rico e as a√ß√µes anteriores para prever onde podem estar os obst√°culos que n√£o s√£o vis√≠veis no momento.

4. **A√ß√£o**:
   - Decide desviar ou continuar com base no estado interno e nas percep√ß√µes atuais.

Esse rob√¥ n√£o depende apenas das informa√ß√µes atuais; ele usa seu estado interno e modelos para operar de forma eficiente.

### Agentes Baseados em Objetivos

Os **Agentes Baseados em Objetivos** s√£o projetados para tomar decis√µes orientadas a alcan√ßar um ou mais **objetivos**. Eles n√£o se limitam a reagir ao ambiente, mas consideram uma s√©rie de a√ß√µes necess√°rias para atingir uma meta.

#### Caracter√≠sticas principais:
1. **Tomada de decis√£o orientada a objetivos**:
   - O agente decide suas a√ß√µes com base no objetivo final a ser alcan√ßado, considerando o impacto das a√ß√µes no longo prazo.
2. **Considera√ß√£o do futuro**:
   - Avaliam como as a√ß√µes atuais influenciar√£o os estados futuros, diferentemente das regras de a√ß√£o reativas.
3. **Flexibilidade**:
   - O conhecimento expl√≠cito sobre os objetivos torna o agente mais adapt√°vel a mudan√ßas, pois esse conhecimento pode ser atualizado sem a necessidade de redesenhar o agente.

#### Limita√ß√µes:
- Menor efici√™ncia em termos de tempo de decis√£o, devido ao processamento necess√°rio para planejamento.
- Requer um ambiente suficientemente compreens√≠vel para calcular as a√ß√µes necess√°rias.

#### Funcionamento

1. **Defini√ß√£o do objetivo**:
   - O agente possui metas claras que deseja alcan√ßar, como chegar a um destino ou realizar uma tarefa espec√≠fica.
2. **Planejamento**:
   - O agente utiliza algoritmos de planejamento para determinar a sequ√™ncia de a√ß√µes que o levar√° do estado atual ao estado objetivo.
3. **Execu√ß√£o**:
   - Com base no planejamento, o agente realiza as a√ß√µes de forma sequencial, ajustando conforme necess√°rio.

#### Exemplo: Rob√¥ Entregador em um Armaz√©m

Imagine um rob√¥ projetado para coletar e entregar pacotes em um armaz√©m:

1. **Objetivo**:
   - Entregar um pacote do ponto A ao ponto B.
2. **Tomada de decis√£o**:
   - O rob√¥ considera o objetivo final e planeja a rota mais eficiente, levando em conta o layout do armaz√©m e poss√≠veis obst√°culos.
3. **Flexibilidade**:
   - Se o objetivo mudar (como um novo local de entrega), o rob√¥ pode recalcular seu plano sem precisar ser reprogramado.

Esse agente √© mais flex√≠vel, pois seu planejamento e execu√ß√£o est√£o sempre alinhados √†s metas definidas, permitindo ajustes din√¢micos.

### Agentes Utilit√°rios

Os **Agentes Utilit√°rios** s√£o projetados para tomar decis√µes que maximizem a **qualidade da solu√ß√£o** ou **performance** do sistema. Eles utilizam uma **fun√ß√£o utilidade** para avaliar e comparar diferentes a√ß√µes ou estados poss√≠veis.

#### Caracter√≠sticas principais:
1. **Qualidade al√©m do objetivo**:
   - Um objetivo pode ser atingido de v√°rias formas, mas os agentes utilit√°rios buscam atingir o objetivo da forma mais eficiente ou desej√°vel.
2. **Fun√ß√£o utilidade**:
   - Mede o qu√£o desej√°vel √© um estado ou a√ß√£o, atribuindo valores que permitem compara√ß√µes entre alternativas.
3. **Gerenciamento de objetivos conflitantes**:
   - Capaz de lidar com m√∫ltiplos objetivos que podem competir entre si, atribuindo prioridades e resolvendo conflitos.
4. **An√°lise de probabilidade vs. import√¢ncia**:
   - Avalia a probabilidade de sucesso de uma a√ß√£o em rela√ß√£o √† sua relev√¢ncia para maximizar o resultado.


#### Maximiza√ß√£o da Utilidade Esperada

Os agentes utilit√°rios utilizam modelos probabil√≠sticos para prever o impacto de suas a√ß√µes e escolhem a op√ß√£o que oferece o maior **retorno esperado** em termos de utilidade.

#### Funcionamento

1. **Defini√ß√£o da fun√ß√£o utilidade**:
   - Define uma m√©trica clara que representa o desempenho desejado do agente.
2. **Avalia√ß√£o de a√ß√µes e estados**:
   - O agente atribui um valor de utilidade a cada estado ou a√ß√£o poss√≠vel.
3. **Escolha da melhor a√ß√£o**:
   - A partir da compara√ß√£o dos valores de utilidade, o agente escolhe a a√ß√£o que maximiza o resultado esperado.

#### Exemplo: Sistema de Recomenda√ß√£o

Imagine um sistema de recomenda√ß√£o de filmes:

1. **Objetivo**:
   - Sugerir um filme que o usu√°rio provavelmente gostar√°.
2. **Fun√ß√£o utilidade**:
   - Mede a satisfa√ß√£o esperada do usu√°rio com base em prefer√™ncias anteriores, classifica√ß√µes de filmes e comportamento de outros usu√°rios.
3. **Maximiza√ß√£o**:
   - Avalia as probabilidades de diferentes op√ß√µes serem bem recebidas e recomenda o filme com a maior utilidade esperada.

Esse sistema equilibra objetivos conflitantes, como popularidade do filme, diversidade de g√™nero e satisfa√ß√£o esperada, para otimizar a experi√™ncia do usu√°rio.

### Aprendizado de Agentes

O **aprendizado de agentes** permite que o agente melhore continuamente seu desempenho ao longo do tempo, ajustando suas a√ß√µes com base no feedback obtido.

#### Componentes principais:

1. **Elemento de aprendizado**:
   - Modifica o **elemento de performance** com base no feedback fornecido pelo **elemento cr√≠tico**.
   - Objetivo: Melhorar o desempenho do agente.

2. **Elemento de performance**:
   - Implementa as a√ß√µes externas do agente, considerando recompensas (pr√™mios) ou puni√ß√µes (penalidades) associadas √†s suas decis√µes.
   - Objetivo: Maximizar a efici√™ncia e atingir os objetivos do agente.

3. **Elemento cr√≠tico**:
   - Avalia o desempenho do agente comparando-o a um padr√£o pr√©-definido.
   - Fornece feedback ao **elemento de aprendizado**, indicando onde o agente pode melhorar.

4. **Gerador de problemas**:
   - Explora novas possibilidades para encontrar solu√ß√µes melhores, mesmo quando as solu√ß√µes atuais s√£o funcionais.
   - Ajuda o agente a evitar ficar preso em um desempenho sub√≥timo (explora√ß√£o vs. explora√ß√£o).


#### Funcionamento

1. O agente executa uma a√ß√£o no ambiente por meio do **elemento de performance**.
2. O **elemento cr√≠tico** avalia o impacto dessa a√ß√£o e fornece feedback ao **elemento de aprendizado**.
3. O **elemento de aprendizado** ajusta as regras ou par√¢metros do agente para melhorar suas decis√µes futuras.
4. O **gerador de problemas** prop√µe novas estrat√©gias ou explora solu√ß√µes alternativas para superar limita√ß√µes do agente.


#### Exemplo: Assistente Virtual Aprendendo Prefer√™ncias do Usu√°rio

Imagine um assistente virtual que aprende a organizar compromissos de um usu√°rio:

1. **Elemento de performance**:
   - Sugere hor√°rios e organiza compromissos com base nas prefer√™ncias iniciais do usu√°rio.
2. **Elemento cr√≠tico**:
   - Avalia a satisfa√ß√£o do usu√°rio com as sugest√µes, considerando feedback expl√≠cito (coment√°rios) e impl√≠cito (aceita√ß√£o ou rejei√ß√£o das sugest√µes).
3. **Elemento de aprendizado**:
   - Ajusta a programa√ß√£o para oferecer sugest√µes mais precisas, baseando-se no feedback recebido.
4. **Gerador de problemas**:
   - Testa novos hor√°rios ou formatos de organiza√ß√£o para otimizar a agenda, mesmo que o m√©todo atual funcione bem.

### Representa√ß√£o de Estados

A **representa√ß√£o de estados** descreve como o conhecimento sobre o ambiente ou o problema √© organizado e armazenado em um agente. Diferentes representa√ß√µes oferecem vantagens dependendo do tipo de aplica√ß√£o e do n√≠vel de complexidade do problema.

#### Tipos de Representa√ß√£o de Estados

#### 1. Representa√ß√£o At√¥mica
- Cada estado √© tratado como uma entidade √∫nica e indivis√≠vel.
- **Exemplos de aplica√ß√£o**:
  - Jogos (xadrez, Go).
  - Pesquisa em espa√ßos de estados.
  - Modelos de Markov Ocultos (HMMs) e Processos de Decis√£o de Markov (MDPs).

#### 2. Representa√ß√£o Fatorial
- Um estado √© descrito por um conjunto de vari√°veis ou fatores que representam suas caracter√≠sticas.
- **Exemplos de aplica√ß√£o**:
  - Algoritmos de satisfa√ß√£o de restri√ß√µes (CSPs).
  - L√≥gica proposicional.
  - Machine learning.
  - Redes Bayesianas.

#### 3. Representa√ß√£o Estruturada
- Os estados possuem componentes inter-relacionados descritos por modelos estruturados ou relacionais.
- **Exemplos de aplica√ß√£o**:
  - Bancos de dados relacionais.
  - L√≥gica de primeira ordem.
  - Modelos probabil√≠sticos de primeira ordem.
  - Processamento de linguagem natural.

#### Mapeamento de Representa√ß√µes de Estados

#### 1. Representa√ß√£o Local
- Rela√ß√£o **um-para-um** entre conceitos e localiza√ß√£o na mem√≥ria.
- **Vantagens**: Clareza e facilidade de manipula√ß√£o.
- **Desvantagens**: Vulner√°vel a ru√≠dos e perdas.

#### 2. Representa√ß√£o Distribu√≠da
- Representa√ß√£o redundante em m√∫ltiplos locais ou vari√°veis.
- **Vantagens**: Robustez contra ru√≠dos e falhas.
- **Desvantagens**: Mais complexa de interpretar.

#### Compara√ß√£o

| **Tipo de Representa√ß√£o**   | **Caracter√≠sticas**                                              | **Aplica√ß√µes Comuns**                                      |
|-----------------------------|------------------------------------------------------------------|----------------------------------------------------------|
| Representa√ß√£o At√¥mica       | Sem estrutura interna, cada estado √© uma entidade √∫nica.        | Jogos, pesquisa em espa√ßos de estados, modelos de Markov. |
| Representa√ß√£o Fatorial      | Estado descrito por vari√°veis ou fatores interdependentes.      | CSPs, redes Bayesianas, aprendizado de m√°quina.          |
| Representa√ß√£o Estruturada   | Captura rela√ß√µes complexas entre componentes do estado.         | Bancos de dados relacionais, linguagem natural.          |

#### Exemplo: Planejamento em um Jogo

1. **Representa√ß√£o At√¥mica**:
   - Cada posi√ß√£o do tabuleiro √© um estado √∫nico.
2. **Representa√ß√£o Fatorial**:
   - O estado do jogo √© representado por vari√°veis, como posi√ß√µes das pe√ßas e o turno.
3. **Representa√ß√£o Estruturada**:
   - Captura rela√ß√µes entre pe√ßas no tabuleiro, como amea√ßas e alinhamentos estrat√©gicos.

---

## üí° **Exemplos Pr√°ticos**

- **Exemplo 1**: [Descreva o exemplo dado em aula, explique o contexto]
- **Exemplo 2**: [Adicione mais exemplos com explica√ß√µes]

---

## ‚ùì **D√∫vidas**

- [Liste suas d√∫vidas aqui para revisar ou perguntar em outro momento]
- [Outra d√∫vida importante]

---

## üîó **Refer√™ncias ou Leituras Complementares**

- [Link ou livro recomendado]
- [Artigos mencionados durante a aula]

---

## üóÇÔ∏è **Tarefas ou Atividades**

- [Descreva a tarefa ou atividade passada]
- [Adicione prazos ou orienta√ß√µes importantes]

---

## üó£Ô∏è **Discuss√µes ou Reflex√µes**

- [Espa√ßo para voc√™ refletir sobre o conte√∫do da aula, fazer conex√µes com outros temas ou anotar coment√°rios pessoais]
