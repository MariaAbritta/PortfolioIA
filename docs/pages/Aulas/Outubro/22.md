# üìö Aula - Hist√≥ria da Intelig√™ncia Artificial

## üîë **Conceitos-Chave**

- **[Conceito 1]**: [Defini√ß√£o ou explica√ß√£o]
- **[Conceito 2]**: [Defini√ß√£o ou explica√ß√£o]

---

## ‚úçÔ∏è **Anota√ß√£o da Aula**

### O in√≠cio da intelig√™ncia artificial (1943-1956)
- Warren McCulloch e Walter Pitts (1943):
  - Criaram um modelo de neur√¥nios onde cada neur√¥nio pode estar "ligado" ou "desligado".
  - Um neur√¥nio √© ativado ("ligado") quando √© estimulado por um n√∫mero suficiente de neur√¥nios vizinhos.
  - Todos os conectivos l√≥gicos (AND, OR, NOT, etc.) podem ser implementados por redes neurais simples.
  - Redes bem definidas t√™m a capacidade de aprender.
- Donald Hebb (1949):
  - Demonstrou uma regra de atualiza√ß√£o simples para ajustar as for√ßas de conex√£o entre neur√¥nios.
  - Essa regra √© conhecida como aprendizagem Hebbiana.
- Harvard: Marvin Minsky e Dean Edmonds:
  - Constru√≠ram o SNARC, o primeiro computador baseado em rede neural.
- Alan Turing:
  - Introduziu conceitos fundamentais como:
    - Teste de Turing (avalia√ß√£o da capacidade de uma m√°quina de exibir comportamento inteligente).
    - Aprendizado de M√°quina (Machine Learning).
    - Algoritmos Gen√©ticos.
    - Aprendizado por Refor√ßo (Reinforcement Learning).
  - Turing sugeriu que seria mais eficiente desenvolver uma IA de n√≠vel humano criando algoritmos de aprendizado e ensinando a m√°quina, em vez de programar sua intelig√™ncia manualmente.
- Dartmouth Summer Research Project on Artificial Intelligence (DSRPAI) - 1956:
  - Primeiro evento dedicado √† Intelig√™ncia Artificial.
  - Organizado por John McCarthy e Marvin Minsky em 1956.
  - Reuniu pesquisadores de diferentes √°reas para discutir o futuro da IA.
  - Foi durante este evento que o termo "Intelig√™ncia Artificial" foi cunhado por John McCarthy.

### Entusiasmo inicial e grandes expectativas (1952-1969):
- Herbert Gelernter (1959):
  - Criou o Provador do Teorema da Geometria, que resolvia teoremas complexos, equivalentes aos que estudantes de matem√°tica encontrariam desafiadores.
- Arthur Samuel (~1956):
  - Utilizou aprendizado por refor√ßo para ensinar computadores a jogar damas em um n√≠vel competitivo (amador forte).
- Problemas de micro-mundo:
  - Inclui exemplos como o blocks world, um ambiente simplificado usado para testar conceitos de IA.
- Redes Neurais:
  - Modeladas por McCulloch e Pitts.
- Perceptrons (Frank Rosenblatt - 1962):
  - Desenvolvimento inicial de redes neurais artificiais baseadas em perceptrons, capazes de aprendizado simples.

### Uma dose de realidade (1966-1973)
- Limita√ß√µes da IA:
  - Capaz de resolver problemas simples, mas incapaz de lidar com problemas complexos.
- Minsky e Papert (1969):
  - Demonstraram que, embora os perceptrons pudessem aprender o que podiam representar, sua capacidade de representa√ß√£o era muito limitada.
- Problema da porta XOR:
  - Mostrou que perceptrons simples n√£o conseguiam resolver problemas n√£o linearmente separ√°veis, como a fun√ß√£o XOR.
  - Isso levou a um decl√≠nio no entusiasmo pela IA, conhecido como o Inverno da IA.

### Sistemas Especialistas (1969-1986)
- In√≠cio das pesquisas em IA:
  - Foco inicial em prop√≥sito geral com m√©todos fracos.
  - Solu√ß√£o encontrada: foco em problemas espec√≠ficos usando conhecimento de dom√≠nio espec√≠fico.
- DENDRAL (1969):
  - Criado por Ed Feigenbaum, Bruce Buchanan, e Joshua Lederberg.
  - Sistema especialista para inferir estruturas moleculares com base em dados de espectr√¥metros de massa.
- MYCIN:
  - Sistema especialista com 450 regras desenvolvido para diagnosticar infec√ß√µes no sangue.
  - Teve um desempenho compar√°vel a especialistas e superior a m√©dicos juniores.
- R1 (1982):
  - Primeiro sistema especialista comercial bem-sucedido, implementado na Digital Equipment Corporation.
  - O programa ajudava na configura√ß√£o de pedidos de novos sistemas de computador.
  - Em 1986, gerou uma economia de aproximadamente US$ 40 milh√µes por ano para a empresa.
- Crescimento da Ind√∫stria de IA:
  - A ind√∫stria de IA cresceu de milh√µes de d√≥lares em 1980 para bilh√µes de d√≥lares em 1988.
  - Surgiram centenas de empresas focadas em:
    - Sistemas especialistas.
    - Sistemas de vis√£o.
    - Rob√¥s.
    - Software e hardware especializado para aplica√ß√µes em IA.
- Inverno da IA:
  - Um per√≠odo de decl√≠nio no interesse e investimentos em IA, iniciado em 1987.
  - Muitas empresas fecharam devido √† incapacidade de cumprir promessas extravagantes feitas sobre suas tecnologias.
- Desafios enfrentados:
  - Construir e manter sistemas especialistas para dom√≠nios complexos tornou-se dif√≠cil.
  - M√©todos de racioc√≠nio utilizados pelos sistemas falharam ao lidar com a incerteza.
  - Sistemas n√£o tinham a capacidade de aprender com a experi√™ncia, limitando sua efic√°cia.
  
### O retorno das redes neurais (1986-presente)
- Redescoberta do aprendizado de retropropaga√ß√£o:
  - Em meados da d√©cada de 1980, pelo menos quatro grupos diferentes redescobriram o algoritmo de aprendizado por retropropaga√ß√£o, originalmente desenvolvido nos anos 1960.
- Modelos conexionistas:
  - Formam conceitos internos que s√£o mais adequados para representar o mundo real.
  - Capazes de aprender com exemplos, adaptando-se a novos dados.
- Desempenho adapt√°vel:
  - Devido √† sua natureza adapt√°vel, esses modelos podem ter um melhor desempenho em exemplos futuros, permitindo um aprendizado cont√≠nuo e aprimorado.

### Racioc√≠nio probabil√≠stico e aprendizado de m√°quina (1987-presente)
- David McAllester (1998):
  - Observou que, no in√≠cio da IA, havia a cren√ßa de que novas formas de computa√ß√£o simb√≥lica, como frames e redes sem√¢nticas, tornariam obsoleta a teoria cl√°ssica.
  - Isso levou a um isolacionismo em que a IA se separou do restante da ci√™ncia da computa√ß√£o.
  - Destacou a import√¢ncia de integrar √°reas como:
  - Aprendizado de m√°quina com teoria da informa√ß√£o.
  - Racioc√≠nio incerto com modelagem estoc√°stica.
  - Busca com otimiza√ß√£o e controle cl√°ssicos.
  - Racioc√≠nio automatizado com m√©todos formais e an√°lise est√°tica.
- Reconhecimento de fala (anos 80):
  - Cadeias de Markov ocultas dominaram os problemas nessa √°rea.
- Judea Pearl (1988):
  - Utilizou redes Bayesianas para representar conhecimento incerto e desenvolveu algoritmos pr√°ticos para racioc√≠nio probabil√≠stico.
- Rich Sutton (1988):
  - Introduziu a ideia de aprendizado por refor√ßo, que √© aplicado em √°reas como Processos de Decis√£o de Markov.
- Uni√£o gradual de subcampos:
  - Integra√ß√£o de √°reas como vis√£o computacional, rob√≥tica, reconhecimento de fala, sistemas multiagentes e processamento de linguagem natural.

### Big Data (2001-presente)
- Avan√ßos em computa√ß√£o:
  - O aumento do poder de computa√ß√£o e a cria√ß√£o da World Wide Web facilitaram a forma√ß√£o de conjuntos de dados muito grandes, conhecido como Big Data.
- Tipos de dados:
  - Esses conjuntos incluem:
    - Trilh√µes de palavras de texto.
    - Bilh√µes de imagens.
    - Bilh√µes de horas de fala e v√≠deo.
    - Dados gen√¥micos.
    - Dados de rastreamento de ve√≠culos.
    - Fluxo de dados.
    - Dados de redes sociais.
- Desenvolvimento de algoritmos:
  - O surgimento do Big Data levou ao desenvolvimento de algoritmos de aprendizado projetados especificamente para aproveitar conjuntos de dados grandes, permitindo melhores an√°lises e insights.

### Deep Learning (2011‚Äìpresente)
- Defini√ß√£o de Aprendizado Profundo:
  - Refere-se ao aprendizado de m√°quina que utiliza v√°rias camadas de elementos de computa√ß√£o simples e ajust√°veis.
- Hist√≥rico:
  - Embora a t√©cnica tenha sido utilizada desde a d√©cada de 1970, foi em 2011 que os m√©todos de aprendizado profundo come√ßaram a ganhar tra√ß√£o significativa.
- √Åreas de aplica√ß√£o:
  - Inicialmente, teve sucesso no reconhecimento de fala e, em seguida, no reconhecimento visual de objetos.
- Competi√ß√£o ImageNet (2012):
  - Um sistema de aprendizado profundo desenvolvido pelo grupo de Geoffrey Hinton na Universidade de Toronto (Krizhevsky et al., 2013) alcan√ßou uma melhoria dram√°tica na classifica√ß√£o de imagens em mil categorias, superando sistemas anteriores.
- Desempenho Superior:
  - Desde ent√£o, os sistemas de aprendizado profundo:
    - Superaram o desempenho humano em algumas tarefas de vis√£o.
    - Tamb√©m mostraram ganhos not√°veis em reconhecimento de fala, tradu√ß√£o de m√°quina, diagn√≥sticos m√©dicos, e jogos como o AlphaGo, que venceu o campe√£o mundial humano em 2016.
- Ressurgimento do Interesse:
  - Esses sucessos levaram a um ressurgimento do interesse pela IA entre:
    - Estudantes.
    - Empresas.
    - Investidores.
    - Governos.
    - M√≠dia e p√∫blico em geral.

### Neats vs. Scruffies
- Neats:
  - Defendem que as teorias de IA devem ser baseadas em rigor matem√°tico e fundamenta√ß√£o te√≥rica s√≥lida.
- Scruffies:
  - Preferem uma abordagem mais experimental, onde muitas ideias s√£o testadas por meio da escrita de programas, avaliando o que funciona na pr√°tica.
- Hist√≥rico da Distin√ß√£o:
  - Esta distin√ß√£o surgiu nos anos 70 e foi debatida at√© meados dos anos 80.
  - Nas d√©cadas de 1990 e XXI, a pesquisa em IA passou a adotar predominantemente abordagens "Neats".
- Ressurgimento dos Scruffies:
  - A √™nfase atual no aprendizado profundo pode indicar um retorno √†s abordagens Scruffies, onde a experimenta√ß√£o e a pr√°tica s√£o mais valorizadas.
---

## üí° **Exemplos Pr√°ticos**

- **Exemplo 1**: [Descreva o exemplo dado em aula, explique o contexto]
- **Exemplo 2**: [Adicione mais exemplos com explica√ß√µes]

---

## ‚ùì **D√∫vidas**

- [Liste suas d√∫vidas aqui para revisar ou perguntar em outro momento]
- [Outra d√∫vida importante]

---

## üîó **Refer√™ncias ou Leituras Complementares**

- [IA Perplexity](https://www.perplexity.ai/)

---

## üóÇÔ∏è **Tarefas ou Atividades**

- [Descreva a tarefa ou atividade passada]
- [Adicione prazos ou orienta√ß√µes importantes]

---

## üó£Ô∏è **Discuss√µes ou Reflex√µes**

- [Espa√ßo para voc√™ refletir sobre o conte√∫do da aula, fazer conex√µes com outros temas ou anotar coment√°rios pessoais]
