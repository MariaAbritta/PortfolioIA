# A Jornada da Inteligência Artificial: Entre a Racionalidade, Ética e o Futuro da Otimização - Resenha crítica da Parte 1 do Curso de Inteligência Artificial da UnB FGA

## Introdução

Nesta resenha, apresentarei uma análise crítica de todo o material explicado pelo professor Fabiano Araujo Soares, material esse escrito por ele, do semestre 2024.2. Este material trata dos assuntos de:

1. Introdução à inteligência artificial
2. Histórico,
3. Estado da arte
4. Benefícios e riscos
5. Agentes inteligentes
6. Ambientes e racionalidade.

O objetivo desta resenha é examinar os principais pontos e oferecer uma avaliação crítica sobre o tema na minha visão, uma visão de uma aluna no penúltimo período de Engenharia de Software.

## O que é inteligência artificial?

Começamos a matéria tentando definir o que é a Inteligência Artifical (IA), o que pe um conceito que, por mais que eu leie diversas obras, ainda sinto que nós, seres humanos, não conseguimos definir ela por inteiro. É importante ressaltar que nem tudo que é inteligente, é IA e também nem tudo que tente copiar o as ações humanas, tal como raciocíno ou falas, é inteligência artificial. Vamos elaborar...

#### 1. Nem tudo que é inteligente é IA

- **Um ser humano** pode ser muito inteligente, temos diversos exemplos ao decorrer da história, como Bill Gates e Sigmund Freud. A inteligência vai muito além da sabedoria, envolve emoção, intuição e experiências que são MAIS do que processar dados. Um exemplo é **um médico experiente** pode tomar decisões complexas com base em seu conhecimento e experiência, utilizando o raciocínio ético e emocional, algo que **não pode ser simulado por uma IA simples**.

#### 2. Nem tudo que tenta copiar as ações humanas é IA

- Existem diversos programas de reconhecimento de voz, como algum atendente automático, que imitam a fala humana, não são IA. **Não têm verdadeira compreensão ou raciocínio** sobre o que estão "falando". Eles **executam ações programadas** com base em comandos específicos. Mesmo podendo imitar algo específico do ser humano, não possuem a capacidade de **aprender ou adaptar** suas respostas de maneira autônoma e inteligente.

Por mais que esses exemplos sejam muito simples, quero mostrar que não é fácil definir a IA com frases rasas e simples. Particulamente, gostaria de citar o que escrevi no meu Trabalho de Conclusão de Curso (TCC) sobre a definição de IA:

> **As dificuldades em definir IA não são, portanto, o resultado de alguma deficiência ou descuido, mas surgem do fato de que fomos incapazes de determinar precisamente qual inteligência desejaríamos replicar artificialmente (Sheikh, 2023). Dessa forma, definimos a Inteligência Artificial como sistemas que exibem comportamento inteligente ao analisar seu ambiente e tomar ações – com algum grau de autonomia – para atingir objetivos específicos. (Sheikh, 2023)** ➢ Mission AI - The New System Technology; Haroon Sheikh & Corien Prins & Erik Schrijvers

Essa interrogação que causa na nossa cabeça para diferenciar e definir o que é IA e o que é Inteligência Humana é uma reflexão que sempre temos quando vamos comentar do poder que a IA poder alcançar ou fazer. É importante que questionemos até que ponto os sistemas de IA devem tentar replicar o comportamento humano e até que ponto a racionalidade por si só pode ser suficiente para alcançar os objetivos desejados.

### Fidelidade à performance humana x Racionalidade

Debater sobre a fidelidade à performance humana e racionalidade é uma questão muito potente no desenvolvimento de IAs, porque porque ter fidelidade à performance humana significa replicar os comportamentos, raciocínios e emoções humanas, porém realizadas por sistemas artificias, imitando o que o humano faz. Queremos algo que seja como nós? Pensar como nós torna essa inteligência como nós? Queremos algo que vá além da nossa performance? Acredito que todas as respostas para essas respostas são: "Não sabemos".

Vamos para um caminho que leva a IA a se paroximar de como nós, seres humanos, pensamos e agimos. Entramos em experimentos como os de **Warren McCulloch** e **Walter Pitts** nos anos 40:

> **Warren McCulloch e Walter Pitts, em 1943, criaram o primeiro modelo matemático de neurônio artificial, um marco fundamental para o desenvolvimento das redes neurais. Sua pesquisa se baseou na biologia dos neurônios e na lógica matemática, resultando em um modelo computacional que simula como os neurônios processam informações. Esse modelo de neurônio artificial, chamado de "modelo de McCulloch-Pitts", usava entradas binárias, pesos sinápticos e uma função de ativação de tipo "tudo ou nada", muito semelhante ao comportamento dos neurônios biológicos.** ➢ Bertazzi Junior, Waldir. "Redes Neurais 1: O primeiro modelo de neurônio artificial de McCulloch e Pitts."

- Eles propuseram que a atividade de um neurônio seria ativada quando a soma das entradas (consideradas como sinais elétricos) superasse um limiar específico. Esse modelo serviu como base para a construção de redes neurais simples e para o desenvolvimento de dispositivos computacionais que pudessem realizar cálculos lógicos, como portas AND, OR e NOT.

Do outro lado da moeda, a racionalidade na IA tem o objetivo de criar agentes que tomem decisões baseadas em lógica e informações disponíveis. Esse conceito de "racionalidade" pode confundir leitores iniciantes no mundo da IA. A **racionalidade** falada aqui é sobre "fazer a coisa certa", tomar a melhor decisão entre todas que a IA tiver, não algo que precisa imitar a cognição humana para ser eficaz. Isso reflete que, até as caracterísitcas consideradas humanas, como a racionalidade, não´são os mesmos conceitos quando são tragos para o mundo de software. A ideia aqui é que a IA tenha _racionalidade suficiente_ para que tenha um desempenho eficaz no que foi proposto.

Gosto dessa dualidade que o professor Fabiano trouxe, me fez pensar: _"Até que ponto devemos exigir que a IA imite nossa mente humana?"_ ou sera que _"a verdadeira inteligência artificial está na capacidade de resolver problemas por meio de raciocínio lógico, sem precisar se preocupar em parecer humano?"_. Mas afinal, o que seria **raciocínio**?

### Raciocínio x Comportamento

Debater sobre esses dois conceitos dentro de IA envolve uma importante distinção nesses dois conceitos, pois podem levar a erros de pensamentos

- **Raciocínio**: É a capacidade de processar informação de maneira racional e lógica, para tomar algum tipo de decisão. Na IA, esse "raciocínio" é automatizado, onde sistemas são projetados para resolver problemas, interferir e deduzir alguma decisão baseada em uma banco de dados de informações.

  > **Os nossos conhecimentos são a reunião do raciocínio e experiência de numerosas mentes.** ➢ Ralph Waldo Emerson

- **Comportamento**: São respostas ou ações. Um comportamento inteligente é muitas vezes definido como algo que resulta de interação com o ambiente. O foco é fazer "a coisa certa" definida para atingir um objetivo, sem mostrar como foi feito o raciocínio para chegar naquela ação.

Conseguimos ver que a maior diferena entre os dois conceitos que eu apresentei é em relação ao processo cognitivo e capacidade de deduzir a partir de infomrações versus responder e ter ações de acordo com um ambiente. Isso tem uma linha muito tênue, porque pensando em larga escala, o que é certo e errado para você, pode não ser para mim. Um agente de guerra robotizado e inteligente, tem sua definição de "coisa certa" exterminar quem não é do seu lado da guerra... matar poderia der um comportamento correto? E como criamos um raciocínio para essa IA entender quem matar ou não? Isso é parte do desafio do alinhamento de valores, onde um agente pode entender a lógica de uma situação, mas seus comportamentos podem não estar alinhados com os objetivos humanos ou a ética.

### Modelo Padrão

Esse modelo se refere justamente a uma abordagem que prioriza a criação de agentes que tenham ações racionais para conseguir chegar em um objeivo pré-definido. A ideia central é o que apresentei em "comportamento", desenvolver um sistema que faça a "coisa certa", em que essa "coisa certa" é definida pelos objetivos estabelecidos para o agente.

#### Componentes do Modelo Padrão

1. **Agentes Racionais**

- São quem percebe o ambiente e vai tomar a decião para maximiar o desempenho com base nas informações que deram.
- Um agente racional não necessariamente toma a _melhor decião_, mas a melhor decisão possível com base nos dados dele.

2. **Percepção e Ação**

- Ele usa sensores para capturar os dados do ambiente e interagir com ele. Um carro autônomo usa câmeras/senores para perceber os carro e outros obstáculos, ajustando sua direção.

3. **Definição de Objetivos**

- O seu comportamento é guiado por objetivos claros que são definidos por nós, humanos.

4. **Avaliação do Desempenho**

- tiliza métricas para avaliar o quão bem o agente está, em relação a atingir suas metas.

Existem alguns poréns em criar um **Modelo Padrão**, o agente pode interpretar metas de forma não esperada, tendo consequências negativas, o ambiente real é mais desafiador e imprevisível do que dentro de um laboratório, dificultando a tomada de decisão e, para mim, a racionalidade, sozinha, não é suficiente para modelar toda a complexidade do comportamento humano ou para alcançar resultados considerados "inteligentes" de forma ampla.

### Fundamentos da Inteligência Artificial

Aqui concentramos todos os princípios teóricos e práticos que ajudam o desenvolvimento e a aplicação de IAs. Existem diversas contribuições além do mundo da tecnologia, como filosofia, economia, psicologia, linguística e mais. Precisamos entender que mesmo a IA sendo algo muito imerso dentro do mundo da tecnologia, ela abrange diversos pontos de diversas disciplinas.

#### Aprendizado de Máquina (Machine Learning)

É um dos pilares modernos da IA, o aprendizado de máquina faz com que os sistemas melhorem com a experiência. Temos:

1. Supervisionado: A partir de exemplos rotulados.
2. Não supervisionado: Descobrindo padrões em dados não rotulados.
3. Aprendizado por reforço: Aprender através de recompensas e punições.
4. Deep Learning: Uso de redes neurais profundas para tarefas complexas, como visão computacional e processamento de linguagem.

#### Processamento de Linguagem Natural (PLN)

Permite que máquinas compreendam, processem e gerem linguagem humana para melhor entendimento de quem solicitou uma ação. Temos:

1. Análise sintática e semântica.
2. Modelos como o GPT (usado em chatbots).
3. Tradução automática e assistentes virtuais.

### Filosofia e Ética

A IA levanta algumas questões, como:

1. Natureza da inteligência: Como replicar de forma ética?
2. Tomada de decisões morais: Especialmente em áreas como saúde e veículos autônomos.
3. Alinhamento de valores: Garantir que os objetivos das máquinas reflitam intenções humanas.

## Histórico

Por mais que pareca que IA é um assunto novo, temos uma história gigantesca por trás dessa tecnologia que hipnotiza quem usa.

### Mitologia e Ficção

A ideia de algo que tenha inteligência mas é algo "não-humano" está presente nas mitologias da humanidade e em ficções. Temos o Golem, da tradição judaica, as criaturas autônomas de Hephaestus, na mitologia grega, a obra de Frankenstein (1818) e os Robôs de Karel Čapek (1921, onde o termo "robô" "nasceu"), ajudaram a popularizar essa ideia e plantar a imaginação para coisas desse cunho

> **"O desenvolvimento de máquinas que superam a inteligência humana é um tema que tem sido explorado na mitologia, na literatura e, agora, na realidade. Essas narrativas frequentemente nos alertam sobre perigos potenciais, oferecendo uma lente para examinar nossas próprias decisões na criação de sistemas inteligentes."** ➢ "Superintelligence: Paths, Dangers, Strategies" (2014), de Nick Bostrom

<img src="/docs/assets/Images/mitologia.png" alt="Exemplo visual dos mitos e ficções citadas" title="Exemplo visual dos mitos e ficções citadas">

É interessante como essas histórias já destacavam como o ser humano gostaria de ter algo que o servisse e que tivesse uma mínima inteligência, além de destacarem também os perigos sobre, como o perigo do controle, o Frankenstein mesmo aterrorizou muito em sua história. 

### O início da inteligência artificial (1943-1956)
  - **Warren McCulloch e Walter Pitts (1943)**: Criaram o primeiro modelo de neurônio artificial, base para as redes neurais.
  - **Alan Turing**: Em 1950, propôs o Teste de Turing para avaliar a inteligência de máquinas.
    - *Teste de Turing*: No teste, um avaliador humano interage com um computador e um ser humano, ambos escondidos de sua vista. Se o avaliador não conseguir distinguir entre a máquina e o humano, a máquina é considerada como tendo passado no teste de "inteligência artificial".
> **A questão de saber se as máquinas podem pensar é uma questão fundamental na filosofia da inteligência artificial, que o teste de Turing pretendia abordar ao determinar se as máquinas poderiam imitar o comportamento humano bem o suficiente para serem indistinguíveis dele.** ➢ Turing, Alan. "Computing Machinery and Intelligence." Mind, 1950
  - **Dartmouth Conference (1956)**: John McCarthy cunhou o termo "Inteligência Artificial", formalizando o campo.

<img src="/docs/assets/Images/warenAlanDartmouth.png" alt="Exemplo visual de Warren & e Walter, Alan e Dartmouth" title="Exemplo visual de Warren & e Walter, Alan e Dartmouth">

É incrível ver como esses primeiros passsos foram visionários para sua época, trazendo uma bagagem maravilhosa para os nossos estudos atuais. 

### Entusiasmo inicial, grandes expectativas (1952-1969)
1. Sistemas capazes de resolver problemas matemáticos e jogar jogos.
2. **Arthur Samuel (1956)**: Criou um programa para jogar damas, precursor do aprendizado por reforço.
  - *Aprendizado por Reforço (Reinforcement Learning - RL)*: Abordagem de aprendizado de máquina onde o agente aprende a tomar decisões pela tentativa e erro, dentro de um ambiente. Sempre recebendo feedback positivo ou negativo (recompensas e penalidades) em cada ação realizada no ambiente.
  - *Exemplo simples em Python*: Aqui, criei um exemplo básico de um agente que aprende a jogar um jogo simples de "bandido de um braço" (ou Multi-Armed Bandit), em que o agente escolhe uma das várias opções e recebe uma recompensa.

```js
class Bandit {
    constructor(probabilidadeDeVitoria) {
        this.probabilidadeDeVitoria = probabilidadeDeVitoria;
    }

    acao() {
        return Math.random() < this.probabilidadeDeVitoria ? 1 : 0;
    }
}

class Agente {
    constructor(numBandidos) {
        this.qValores = new Array(numBandidos).fill(0);
        this.contagens = new Array(numBandidos).fill(0);
    }

    escolherAcao() {
        return this.qValores.indexOf(Math.max(...this.qValores));
    }

    aprender(acao, recompensa) {
        this.contagens[acao] += 1;
        this.qValores[acao] += (recompensa - this.qValores[acao]) / this.contagens[acao];
    }
}

// Inicialização dos bandidos com probabilidades de vitória
const bandidos = [new Bandit(0.8), new Bandit(0.5), new Bandit(0.2)];
const agente = new Agente(bandidos.length);

// Simulação de aprendizado
for (let i = 0; i < 1000; i++) {
    const acao = agente.escolherAcao();
    const recompensa = bandidos[acao].acao();
    agente.aprender(acao, recompensa);
}

console.log(`Escolha final do agente: Bandido ${agente.escolherAcao() + 1}`);
```

  - **Classes**: O método `acao` da classe `Bandit` utiliza `Math.random()` para gerar um número aleatório.
  - **Arrays**: Para armazenar `qValores` e `contagens`, usamos `new Array(numBandidos).fill(0)` para criar arrays preenchidos com zeros.
  - **Execução do loop**: O loop simula a interação entre o `agente` e os `bandidos`.

### Uma dose de realidade (1966-1973)
**O “Inverno da IA” começou** foi um período que houve uma redução drástica de financiamento e entusiasmo sobre o conceito IA. Esse período foi um choque porque revelou a o quão complexo era esse tema e precisaram estagnar para procurar novos caminhos a se seguir para poderem progredir. Esse cenário começou a mudar no final dos anos 90 e início dos anos 2000, com o avanço dos computadores

### Sistemas Especialistas (1969-1986)
Os Sistemas Especialistas (1969-1986) foram uma das primeiras grandes conquistas da inteligência artificial. Eles foram projetados para simular a expertise humana em domínios específicos, como diagnóstico médico, onde mais se popularizou. Esses casos de SEs na medicina é bem complicado, particulamente, eu acredito que seja muito valioso criar sistemas que ajudem o médico a dar diagnósticos mais rapidamente, para agilizar o processo de tratamento ou até mesmo o atendimento dos pacientes, porém o conselho de medicina é bem rígido com essa questão, pois possuem também o medo da substituição da dedução médica por uma dedução artificial, e afinal, estamos tratando de uma tomada de decisão sobre a saúde de alguém.

## Descrição PEAS
O PEAS (**P**erformance, **E**nvironment, **A**ctuators & **S**ensors), são descrições que ajudam a estruturar e melhorar as especificações e os componentes do ambiente de tarefa de maneira clara e objetiva. Vamos entender melhor cada uma das palavras que compõem ele:
1. **Performance (Desempenho)**: Define os critérios usados para avaliar se o agente está alcançando seu objetivo. Exemplos: Pode incluir velocidade, precisão ou eficiência na tarefa.
2. **Environment (Ambiente)**: Descreve o ambiente no qual o agente opera. Pode ser físico (como um robô em um ambiente de fábrica) ou virtual (como um programa de IA jogando um jogo). O ambiente inclui tudo o que o agente pode perceber ou com o qual pode interagir.
3. **Actuators (Atuadores)**: São os dispositivos que permitem ao agente realizar ações no ambiente. Em um robô, isso pode ser motores, braços mecânicos ou outros dispositivos que alteram o estado do ambiente. Em um software, pode ser um comando enviado para um sistema.
4. **Sensors (Sensores)**: São os dispositivos que permitem ao agente perceber o ambiente. Exemplos incluem câmeras, sensores de temperatura, microfones, ou até entradas de dados em sistemas digitais.

### Propriedades do Ambiente de Tarefas
Além do PAES, existem as propriedades do ambiente de tarefas, que ajudam a caracterizar as condições sob  quais o agente deve operar e que influenciam diretamente como ele toma suas decisões. Fiz uma tabela para melhor entendimento:

| **Propriedade**                  | **Explicação**                                                                                                           | **Exemplo**                                                                                              |
|-----------------------------------|-------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|
| **Observabilidade**               | Define o nível de acesso do agente ao estado do ambiente.                                                                |                                                                                                          |
| Totalmente Observável            | O agente tem acesso a todas as informações necessárias sobre o estado atual do ambiente.                                | Jogo de xadrez onde o agente vê todo o tabuleiro.                                                         |
| Parcialmente Observável          | O agente tem acesso apenas a parte das informações, dificultando a decisão.                                              | Robô em uma sala com obstáculos que não pode ver todos ao seu redor.                                      |
| Não Observável                   | O agente não tem informações suficientes sobre o estado do ambiente.                                                   | Sistemas de previsão de mercado financeiro.                                                              |
| **Número de Agentes**             | Define a quantidade de agentes presentes no ambiente.                                                                    |                                                                                                          |
| Agente Único                      | Apenas um agente opera no ambiente, sem interação com outros agentes.                                                  | Agente controlando um robô único.                                                                         |
| Multiagente                       | Vários agentes operam e interagem no ambiente, podendo ser cooperativos ou competitivos.                               | Jogo de estratégia com múltiplos jogadores ou vários robôs autônomos competindo.                          |
| **Determinismo**                  | Define se o ambiente reage de forma previsível ou não a uma ação.                                                      |                                                                                                          |
| Determinístico                    | A mesma ação sempre resulta no mesmo estado do ambiente.                                                                | Jogo de tabuleiro, onde o movimento das peças é sempre previsível.                                       |
| Não Determinístico                | A mesma ação pode ter resultados diferentes, dependendo de fatores externos.                                            | Sistema de navegação de drones, onde o vento pode alterar a trajetória.                                  |
| **Tipo de Decisão**               | Define a dependência das ações em relação ao tempo ou sequência.                                                        |                                                                                                          |
| Episódico                         | Cada ação é independente, e as decisões de um episódio não afetam os próximos.                                          | Tarefa de classificação de imagens, onde cada imagem é analisada separadamente.                         |
| Sequencial                        | As ações de um episódio influenciam as decisões subsequentes, criando uma dependência entre elas.                        | Jogo de xadrez, onde as jogadas afetam o futuro do jogo.                                                 |
| **Mudança no Ambiente**           | Define se o ambiente permanece o mesmo ou muda enquanto o agente decide suas ações.                                      |                                                                                                          |
| Estático                          | O ambiente não muda enquanto o agente está tomando suas decisões.                                                      | Máquina de vendas automática.                                                                            |
| Dinâmico                          | O ambiente pode mudar durante o processo de decisão, exigindo adaptação do agente.                                       | Veículos autônomos, que devem reagir a mudanças no tráfego em tempo real.                                |
| **Tipo de Ambiente**              | Define a natureza do ambiente em termos de complexidade de estados e ações.                                              |                                                                                                          |
| Discreto                          | O ambiente tem um número finito de estados e ações, permitindo uma análise mais controlada.                             | Jogo de damas.                                                                                            |
| Contínuo                          | O ambiente tem um número infinito de estados e ações, tornando o controle mais desafiador.                               | Sistemas de robôs móveis em um ambiente não estruturado.                                                  |
| **Conhecimento sobre o Ambiente** | Define o nível de conhecimento do agente sobre o ambiente e suas leis.                                                  |                                                                                                          |
| Conhecido                         | O agente tem conhecimento completo sobre o ambiente e as leis que o regem.                                              | Sistema de navegação GPS que conhece todas as ruas e destinos.                                           |
| Desconhecido                      | O agente não tem conhecimento completo, o que torna as ações mais arriscadas e imprevisíveis.                           | Agente exploratório em um novo planeta.                                                                  |

### Exemplo com Assistente Virtual Inteligente
A Siri é avaliada pela qualidade e precisão das respostas que ela dá, também como pela eficiência em executar tarefas. O seu ambiente é a interação com o dispositivo do usuário, seja por voz ou comandos textuais. Ela possui sensores como microfone, GPS e sensores de movimento coletam dados para fornecer respostas contextualmente relevantes. Esses componentes e propriedades ajudam a entender como a Siri, como um agente inteligente, interage com o usuário e toma decisões baseadas em dados contextuais e interações contínuas.

- PEAS para o Assistente Virtual **Siri**

| **Componente**       | **Descrição**                                                                                                     |
|----------------------|-------------------------------------------------------------------------------------------------------------------|
| **Performance**       | O sucesso do assistente é medido pela precisão das respostas, capacidade de realizar tarefas e a satisfação do usuário. |
| **Environment**       | O ambiente é a interação do usuário com o dispositivo (iPhone, iPad, Mac) por meio de comandos de voz ou texto.   |
| **Actuators**         | Atores incluem a capacidade de gerar respostas audíveis (falando), interagir com aplicativos, e executar comandos de sistema. |
| **Sensors**           | Sensores incluem o microfone para captar a voz do usuário, GPS para localização, e sensores de movimento (em dispositivos móveis). |

- Propriedades do Ambiente de Tarefas para a **Siri**

| **Propriedade**            | **Explicação**                                                                                                  | **Exemplo**                                              |
|----------------------------|----------------------------------------------------------------------------------------------------------------|----------------------------------------------------------|
| **Observabilidade**         | O agente tem acesso a toda a informação necessária para realizar suas tarefas.                                  | Totalmente observável quando o Siri tem acesso a todos os dados do dispositivo. |
| **Número de Agentes**       | Apenas um agente virtual interage com o usuário a qualquer momento.                                            | Agente único (Siri).                                      |
| **Determinismo**            | A mesma ação sempre gera o mesmo resultado, a menos que fatores externos, como conexão de rede, interferem.     | Determinístico na maioria das respostas, mas pode variar com a conectividade. |
| **Tipo de Decisão**         | O Siri deve adaptar suas respostas com base nas perguntas feitas, e as respostas podem afetar a interação seguinte. | Sequencial, pois as respostas influenciam os próximos passos ou interações. |
| **Mudança no Ambiente**     | O ambiente muda com base nas interações do usuário, como mudança de localização ou de aplicativos abertos.      | Dinâmico, pois o ambiente muda constantemente (ex: mudança de local ou contexto). |
| **Tipo de Ambiente**        | O ambiente de interação é principalmente virtual, mas pode ser sensível ao contexto físico.                     | Discreto, pois há uma série limitada de interações predefinidas. |
| **Conhecimento sobre o Ambiente** | O Siri possui conhecimento sobre dados do dispositivo, aplicativos, e acesso à internet, mas não é infalível.  | Conhecido em parte, mas algumas informações podem ser incertas ou fora de alcance do sistema. |

## Tipos de agente 
Com tantas IAs aparecendo, tantos tipos, foi criado uma classificação entre elas. As classificações são de acordo com a complexidade do processo de tomada de decisão e o nível de planejamento necessário para alcançar um objetivo especificado por nós seres humanos.

### 1. Agentes de Reflexo Simples
  - **Definição**: Um agente de reflexo simples toma decisões com base nas percepções imediatas que recebe. Ele segue uma regra ou condição direta (se-então) sem considerar o histórico ou o estado do ambiente. A decisão é tomada apenas com base na situação atual em que ele está/se encontra.
    - *Exemplo*: Um robô que reage a um obstáculo na frente dele com uma ação simples, como virar para a direita ou para a esquerda, sem considerar outros fatores.
      - O pseudocódigo que fiz para exemplificar um agente de reflexo simples, quando a percepção é `obstacle`, o agente responde virando à direita, indicando uma reação direta ao obstáculo. Se a percepção for `clear`, o agente simplesmente avança em frente. O comportamento é definido por uma simples estrutura de decisão `if-else`, o que caracteriza o agente de reflexo simples: ele apenas reage ao ambiente sem armazenar ou aprender com as interações anteriores. 

```js
function reflexAgent(perception) {
    if (perception === "obstacle") {
        return "turn right";  // Reflexo simples: se há obstáculo, vira à direita
    } else {
        return "move forward";
    }
}

console.log(reflexAgent("obstacle")); // Output: turn right
console.log(reflexAgent("clear")); // Output: move forward
```

### 2. Agentes de Reflexo Baseado em Modelo
  - **Definição**: Esse agente mantém um modelo interno do ambiente para poder tomar decisões mais informadas. Ele usa a percepção atual e o modelo interno para gerar ações. Isso permite que ele reaja de maneira mais inteligente e se adaptar a mudanças no ambiente.
    - *Exemplo*: Um agente de navegação em um jogo que mantém o estado do mapa para saber onde está e como se mover.
      - O pseudocódigo que fiz para exemplificar um agente de reflexo baseado em modelo, inicialmente, possui um estado `initial`. A função `updateModel` é usada para atualizar esse estado com base na percepção do ambiente, como um obstáculo (`obstacle`) ou um caminho livre. Se um obstáculo for detectado, o agente altera seu estado para `obstacle detected`, caso contrário, o estado é atualizado para `clear path`. A função `decideAction` então toma a decisão de agir com base nesse estado: se houver um obstáculo detectado, o agente decide virar à direita; caso contrário, ele segue em frente. Esse tipo de agente vai além do reflexo simples, porque mantém e atualiza um modelo do ambiente, o que permite respostas mais complexas e adaptativas

```js
class ModelBasedAgent {
    constructor() {
        this.state = "initial";  // O agente mantém o modelo de seu estado
    }

    updateModel(perception) {
        if (perception === "obstacle") {
            this.state = "obstacle detected";
        } else {
            this.state = "clear path";
        }
    }

    decideAction() {
        if (this.state === "obstacle detected") {
            return "turn right";  // Se o modelo detectar obstáculo, vira à direita
        } else {
            return "move forward";
        }
    }
}

const agent = new ModelBasedAgent();
agent.updateModel("obstacle");
console.log(agent.decideAction()); // Output: turn right
```

### 3. Agentes Baseados em Objetivos
  - **Definição**: Um agente baseado em objetivos tem um objetivo específico a ser alcançado e escolhe suas ações com base em como alcançar esse objetivo. Ele considera o estado atual, os possíveis futuros estados e escolhe a ação que melhor o aproxima do objetivo desejado.
    - *Exemplo*: Um agente que quer alcançar um destino específico em um mapa e escolhe o caminho mais curto para lá.
      - O pseudocódigo que fiz para exemplificar um agente baseado em objetivo tem uma classe `GoalBasedAgent` que possui um atributo chamado `goal`, que representa o objetivo final do agente. A função `decideAction` verifica a posição atual do agente (passada como argumento) e, se essa posição for igual ao objetivo, o agente retorna `goal reached`, indicando que o objetivo foi alcançado. Caso contrário, ele retorna `move towards goal`, sugerindo que o agente deve continuar se movendo em direção ao objetivo. Este tipo de agente é mais avançado que o agente de reflexo baseado em modelo porque ele não apenas reage ao ambiente, mas tem uma finalidade ou objetivo específico que orienta suas ações. O agente compara sua posição atual com o objetivo e decide o que fazer para alcançar esse objetivo.

```js
class GoalBasedAgent {
    constructor(goal) {
        this.goal = goal;  // O objetivo do agente
    }

    decideAction(currentPosition) {
        if (currentPosition === this.goal) {
            return "goal reached";
        } else {
            return "move towards goal";
        }
    }
}

const agent = new GoalBasedAgent("destination");
console.log(agent.decideAction("start")); // Output: move towards goal
console.log(agent.decideAction("destination")); // Output: goal reached
```

### 4. Agentes Utilitários
  - **Definição**: Agentes utilitários tomam decisões com base em uma função de utilidade, que mapeia diferentes estados ou ações para um valor numérico, representando a "qualidade" de um estado. O agente escolhe a ação que maximiza sua utilidade, em vez de seguir um objetivo fixo ou responder apenas a percepções imediatas.
    - *Exemplo*: Um agente de compras online que escolhe entre diferentes produtos com base em preço, qualidade e avaliações de usuários para maximizar sua satisfação.
      - O pseudocódigo que fiz para exemplificar um agente utilitário, que tem a classe `UtilityAgent` que mantém um conjunto de valores de utilidade para três produtos (`productA`, `productB` e `productC`), representando a "satisfação" ou "preferência" do agente por cada produto. A função `chooseProduct` percorre as utilidades dos produtos e escolhe aquele com o valor mais alto de utilidade, ou seja, o produto mais preferido. O agente começa com um valor inicial de `highestUtility = -Infinity` para garantir que qualquer utilidade seja maior no início. Para cada produto, ele verifica se a utilidade do produto é maior que o valor atual de `highestUtility`. Se for, ele atualiza o produto preferido e a utilidade mais alta. No final, o agente retorna o nome do produto com a maior utilidade. Esse modelo exemplifica como um agente utilitário pode tomar decisões com base em uma avaliação quantitativa das opções disponíveis, buscando maximizar seu benefício ou satisfação (representado pela utilidade).
 
```js
class UtilityAgent {
    constructor() {
        this.utilities = {
            "productA": 80, // utilidade do produto A
            "productB": 90, // utilidade do produto B
            "productC": 70  // utilidade do produto C
        };
    }

    chooseProduct() {
        let bestProduct = null;
        let highestUtility = -Infinity;

        for (let product in this.utilities) {
            if (this.utilities[product] > highestUtility) {
                highestUtility = this.utilities[product];
                bestProduct = product;
            }
        }

        return bestProduct;
    }
}
const agent = new UtilityAgent();
console.log(agent.chooseProduct()); // Output: productB (o mais útil)
```

Esses quatro tipos de agentes são usados em diferentes cenários de inteligência artificial, dependendo da complexidade do ambiente e do tipo de tarefa a ser realizada. Os agentes de reflexo simples são rápidos e eficazes em ambientes estáticos e previsíveis, enquanto os agentes baseados em modelos, objetivos e utilidade são mais adaptáveis e capazes de tomar decisões mais sofisticadas.

## Representação de Estados
A representação de estados é uma parte fundamental dos sistemas de inteligência artificial, já que um agente precisa entender e operar sobre o ambiente que foi colocado.

### Representação

| **Tipo de Representação** | **Descrição** | **Exemplo** |
|---------------------------|---------------|-------------|
| **Atômica**               | A representação atômica é a mais simples, onde cada estado é representado como uma unidade indivisível. O estado é descrito de forma direta, sem dividir em componentes menores. Esta abordagem é usada em ambientes simples ou com poucas variáveis. | Em um jogo de tabuleiro como o "Xadrez", um estado atômico pode ser representado como uma simples configuração do tabuleiro, sem detalhar as posições individuais de cada peça (poderia ser apenas uma string de 64 caracteres representando o estado de cada casa). <br> Exemplo: `["r", "n", "b", "q", "k", "b", "n", "r", ...]` |
| **Fatorial**             | Na representação fatorial, o estado é descrito como um conjunto de variáveis independentes que podem assumir diferentes valores. Cada variável é tratada separadamente, o que pode gerar um número grande de combinações possíveis de estados. É mais eficaz em ambientes com múltiplas dimensões que são independentes umas das outras. | Um exemplo seria o estado de uma máquina de vendas automática onde o estado pode ser representado por variáveis separadas como: quantidade de cada produto em estoque, valor do último pagamento, etc. <br> Exemplo: `estado = {produto1: 10, produto2: 5, saldo: 50}` |
| **Estruturada**           | A representação estruturada envolve a decomposição de estados em uma estrutura mais complexa, como árvores, grafos ou tabelas. Cada componente ou subestado do ambiente é descrito detalhadamente. Isso permite uma melhor compreensão e análise em ambientes complexos, com muitas interações entre variáveis. | Em um jogo de estratégia como o "Go", o estado pode ser representado de forma estruturada, com um gráfico que mapeia cada interseção no tabuleiro e as relações de proximidade entre as peças. <br> Exemplo: Uma tabela que associa as posições dos peões a suas respectivas coordenadas e relações no tabuleiro. |

## Tema do AI Index 2024 - Agente Inteligente para Otimização de Processos de Produção
O problema que proponho é o uso de um agente inteligente para otimizar o processo de produção em uma fábrica, levando em conta o tempo de execução de máquinas, a alocação de recursos e a gestão da logística interna de maneira autônoma e eficiente. O objetivo é aumentar a produção enquanto minimiza custos operacionais e o tempo de inatividade das máquinas.

Descrição PAES

| Elemento       | Descrição                                                                                                                                          |
|----------------|----------------------------------------------------------------------------------------------------------------------------------------------------|
| **Performance** | Maximizar a produção, minimizar os custos operacionais e reduzir o tempo de inatividade das máquinas.                                               |
| **Environment** | Fábrica com diversas linhas de produção, múltiplas máquinas e recursos, como operários, matérias-primas e ferramentas.                             |
| **Actuators**   | Atuação sobre o planejamento de recursos, agendamento de produção e controle das máquinas para otimizar o fluxo de trabalho.                       |
| **Sensors**     | Sensores de tempo de operação das máquinas, sensores de inventário de recursos e materiais, sensores de qualidade do produto em processo.           |

Propriedades do Ambiente de Tarefas

| Propriedade              | Descrição                                                                                                                                                             |
|--------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Observabilidade**       | Parcialmente Observável. O agente tem acesso apenas a dados limitados de cada máquina e processo de produção, não vendo a totalidade do ambiente de produção.          |
| **Número de Agentes**     | Multiagente. Diversos agentes, cada um responsável por uma máquina ou parte do processo de produção, operam em conjunto para otimizar a produção de forma cooperativa.   |
| **Determinismo**          | Não Determinístico. O tempo de operação das máquinas e os atrasos no processo de produção podem variar, afetando o resultado das ações tomadas pelo agente.            |
| **Tipo de Decisão**       | Sequencial. As decisões do agente têm impacto nas próximas etapas do processo de produção, já que cada ação afeta o fluxo da produção subsequente.                   |
| **Mudança no Ambiente**   | Dinâmico. O ambiente muda constantemente à medida que o processo de produção ocorre, com a inserção de novos materiais, máquinas falhando ou necessidades imprevistas. |
| **Tipo de Ambiente**      | Contínuo. O ambiente tem um número infinito de possíveis estados e ações, pois pode variar dependendo de múltiplos fatores, como falhas de máquinas e recursos.        |
| **Conhecimento sobre o Ambiente** | Desconhecido. O agente não tem conhecimento completo sobre todas as variáveis que afetam a produção, como falhas inesperadas ou variações na qualidade do produto. |


### Motivos para essa escolha
A minha escolha de um ambiente parcialmente observável se da a complexidade do processo de produção, onde nem sempre o agente pode ver todos os aspectos do sistema em tempo real. A decisão sequencial reflete o fato de que as escolhas de otimização influenciam diretamente as operações futuras. A dinâmica do ambiente é clara, uma vez que as condições da fábrica (como falhas de máquinas ou mudanças nos pedidos de produção) podem alterar as decisões tomadas pelo agente.

## Conclusão

Com toda essa avaliação, eu concluco que a IA evolui e passso mais alrgos do que conseguimos alcançar. Sinto que somos adultos que cuidamos de um filhote de cachorro que agora quando passeamos com ele, ele corre mais rápido do que nós. Hoje temos diversos conceitos, como os que apresentei: racionalidade e aprendizado de máquina, que batem com os princípios da ética, emrelação a adaptação e os conceitos de "certo" e "errado". Conseguimos ver que a busca pela fidelidade em relação a performance humana revela uma linha tênue entre ser eficiente em decisões, mostrando um desempenho impressionante na resolução de problemas lógicos, e entre a dificuldade em compreender nuâncias entre os contextos fora do seu ambiente e emoções, como o exemplo do robô de guerra que citei. 

Ter um modelo padrão de IA, reflete uma estrutura que permite que os sistemas inteligentes operem dentro de limites previsíveis e controlados. Na minha opinião, a inteligência de um sistema se manifesta quando esse agente é capaz de interagir e se adaptar a ambiêntes não controlados, dinâmicos e imprevisíveis, mas isso ainda continua sendo um desafio. 

É fascinante e, ao mesmo tempo, aterrorizante perceber que, como seres humanos, somos tanto os arquitetos quanto as vítimas de nossa própria criação. A IA não é mais uma ideia distante como os Robôs de Karel Čapek, mas algo totalmente  presente, que está nas nossas vidas de maneiras que ainda acredito que não podemos compreender, impactando tanto positivamente quanto negativamente. Nosso mundo já não é mais o que era, a IA já existe, já evolui e agora somos forçados a conviver com ela. O que nos resta é a responsabilidade de tentar dominar essa criação, mesmo que por muitas vezes pareça que ela nos domina, de manter o que foi criado dentro dos limites de um controle que ainda não conseguimos medir completamente.

Nosso futuro se mistura com a realidade da IA e à medida que evoluimos mais nesse novo mundo, não podemos deixar de ter medo do que será de nós ao entregarmos tanto poder nas mãos de sistemas que, embora criados para servir, podem, no fim, dominar. O amanhã será moldado por nossas próprias mãos, mas em uma realidade que, talvez, jamais imaginamos ter de encarar. A IA está aqui para nos servir e nos ajudar a aprimorar todas as áreas que desejamos, mas não para nos substituir, porque, apesar de sua capacidade de processar informações e otimizar tarefas, ela não possui a **essência humana de criatividade, empatia e julgamento moral**. A verdadeira riqueza da experiência humana reside na nossa capacidade de imaginar o impossível, de tomar decisões complexas e de perceber o valor das relações e do impacto social. Por isso, a IA deve ser vista como uma ferramenta poderosa para complementar nosso potencial, mas **nunca** como um substituto para a nossa humanidade.  

## Referências

- Referência _Resenha crítica_. Disponível em: [https://brasilescola.uol.com.br/redacao/resenha-critica.htm](https://brasilescola.uol.com.br/redacao/resenha-critica.htm)
- Sheikh, H., Prins, C., Schrijvers, E. (2023). Artificial Intelligence: Definition and Background. In: Mission AI. Disponível em: [https://link.springer.com/chapter/10.1007/978-3-031-21448-6_2](https://link.springer.com/chapter/10.1007/978-3-031-21448-6_2)
- Bertazzi Junior, Waldir. "Redes Neurais 1: O primeiro modelo de neurônio artificial de McCulloch e Pitts." Waldir Bertazzi Junior, 22 de outubro de 2018, [https://waldirbertazzijr.com/2018/10/22/redes-neurais-1-o-primeiro-modelo-de-neuronio-artificial-de-mcculloch-e-pitts/.](https://waldirbertazzijr.com/2018/10/22/redes-neurais-1-o-primeiro-modelo-de-neuronio-artificial-de-mcculloch-e-pitts/.)
- Bostrom, Nick. Superintelligence: Paths, Dangers, Strategies. Oxford University Press, 2014. Disponível em: [https://academic.oup.com/book/33540/chapter/287904069](https://academic.oup.com/book/33540/chapter/287904069). Acesso em 19 de novembro de 2024.
- Turing, Alan. "Computing Machinery and Intelligence." Mind, vol. 59, no. 236, 1950, pp. 433-460. Disponível em: [https://academic.oup.com/mind/article/LIX/236/433.](https://academic.oup.com/mind/article/LIX/236/433.). Acesso em 19 de novembro de 2024.
